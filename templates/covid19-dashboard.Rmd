---
title: "COVID-19 Reddit Algo-Tracker" 
output:
    rmdformats::readthedown:
    html_document:
        toc: true
        theme: readthedown
        code_folding: hide
date: '`r format(Sys.Date(), "%B %d, %Y")`'
author: 
    - name: J. Nathan Matias
      affiliation: "<a href='https://citizensandtech.org'>CAT Lab, Cornell University</a>"
    - name: Eric Pennington 
      affiliation: "<a href='https://citizensandtech.org'>CAT Lab, Cornell University</a>"
---
<style type="text/css">
/*#sidebar{background-color:#8d452f}
#sidebar h2{background-color:#ea5324}
h1,h2,h3,h4,h5,h6{color:#ea5324}*/
</style>

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
```


````{r results=FALSE, echo=FALSE}
## load libraries
library(ggplot2)
library(DescTools)
library(knitr)
library(rjson)

## Set visual style
catpalette   <- c("#333333", "#ea5324", "#005073", "#7D868C", "#BDBBBB", "#F2F2F2","#F6F2EB")
covidpalette   <- c("#666666", "#ea5324", "#005073", "#7D868C", "#BDBBBB", "#F2F2F2","#F6F2EB")

chartpalette <- c("#ea5324", "#005073", "#7D868C", "#333333", "#F2F2F2","#BDBBBB", "#F6F2EB")

cat.theme <-  theme_bw() +
              theme(plot.title = element_text(size=13, face="bold", color=catpalette[3]),
                    axis.title.x =element_text(size=10, hjust = -0.01, color = catpalette[1]),
                    axis.title.y =element_text(size=10, color = catpalette[1]),
                    panel.background = element_rect(fill=catpalette[6]))
options(repr.plot.width=6, repr.plot.height=3)

## set directories
HOME.DIR = "/home/nathan/covid-algotracker"
most.recent.folder.name <- as.character(max(as.numeric(SplitPath(Sys.glob(
        file.path(HOME.DIR, "data-archive", "reddit", "[0-9]*")))$filename)))
DATA.FOLDER = file.path(HOME.DIR, "data-archive", "reddit", most.recent.folder.name)
Sys.glob(file.path(DATA.FOLDER, "*"))

######################
## Utility Methods
cat.post <- function(post, ranking){
    cat(paste("<li> <small>(", post['rank_position'], ")",
              "(ðŸ”º",post['ups'], ")",
              "</small> <strong><a href='https://np.reddit.com", 
              post['permalink'], "'>", post['title'], "</a></strong>",
              "<ul><li><small><strong>r/",post['subreddit'], 
              "</strong>. ",
              "(ðŸ’¬",post['num_comments.x'], ") ",
              "Domain: ",post['domain'], ". ",
              "Highest Rank: ", 
              post[paste("max_", ranking, sep="")], ". ",
              "Time on ", ranking, ": ", 
              as.integer(as.numeric(post[paste("front_", ranking, "_seconds", sep="")])/60.),
              " minutes</small></li></ul></small></li>", sep=""))
}

##############################
## load posts and rankings
hot.ranks <- read.csv(file.path(DATA.FOLDER, 
                               paste("rank_timeseries_hot_",
                                     most.recent.folder.name,
                                     ".csv", sep="")))
hot.ranks$snapshot.num <- sequence(rle(as.character(hot.ranks$id))$lengths)


top.ranks <- read.csv(file.path(DATA.FOLDER, 
                               paste("rank_timeseries_top_",
                                     most.recent.folder.name,
                                     ".csv", sep="")))
top.ranks$snapshot.num <- sequence(rle(as.character(top.ranks$id))$lengths)



recent.posts  <- read.csv(file.path(DATA.FOLDER, 
                               paste("promoted_posts_",
                                     most.recent.folder.name,
                                     ".csv", sep="")))

config.json <- fromJSON(file=file.path(DATA.FOLDER, 
                               paste("algotracker-config-",
                                     most.recent.folder.name,
                                     ".json", sep="")))

observation.period.days <- as.integer(round(max(as.POSIXct(top.ranks$rank_time)) - min(as.POSIXct(top.ranks$rank_time))))

#####################################
## Create ranking and post subsets
latest.hot.ranking <- max(hot.ranks$rank_id)
latest.top.ranking <- max(top.ranks$rank_id)

latest.hot.ranks <- subset(hot.ranks, rank_id == latest.hot.ranking & is.na(ups)!=TRUE)
latest.hot.rank.ids <- unique(latest.hot.ranks$id)
latest.top.ranks <- subset(top.ranks, rank_id == latest.top.ranking & is.na(ups)!=TRUE)
latest.top.rank.ids <- unique(latest.top.ranks$id)

latest.hot.posts <- merge(subset(recent.posts, in_latest_snapshot_hot == 1), latest.hot.ranks, by=c("id"))
latest.top.posts <- merge(subset(recent.posts, in_latest_snapshot_top == 1), latest.top.ranks, by=c("id"))

latest.hot.posts <- latest.hot.posts[order(-latest.hot.posts$rank_position),]
latest.top.posts <- latest.top.posts[order(-latest.top.posts$rank_position),]

latest.hot.rank.snapshots <- subset(hot.ranks, id %in% latest.hot.rank.ids)
latest.hot.rank.snapshots$rank.time <- as.POSIXct(latest.hot.rank.snapshots$rank_time, origin="1970-01-01")
latest.hot.rank.snapshots$age.minutes <- as.integer((latest.hot.rank.snapshots$rank.time - max(latest.hot.rank.snapshots$rank.time))/60)

latest.top.rank.snapshots <- subset(top.ranks, id %in% latest.top.rank.ids)
latest.top.rank.snapshots$rank.time <- as.POSIXct(latest.top.rank.snapshots$rank_time, origin="1970-01-01")
latest.top.rank.snapshots$age.minutes <- as.integer((latest.top.rank.snapshots$rank.time - max(latest.top.rank.snapshots$rank.time))/60)
````

<!-- Matomo -->
<script type="text/javascript">
  if (window.location.hostname == "covid-algotracker.citizensandtech.org") {
    var _paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
      var u="https://citizensandtech.matomo.cloud/";
      _paq.push(['setTrackerUrl', u+'matomo.php']);
      _paq.push(['setSiteId', '1']);
      var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
      g.type='text/javascript'; g.async=true; g.defer=true; g.src='//cdn.matomo.cloud/citizensandtech.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
    })();
  }
</script>
<!-- End Matomo Code -->

**How do Reddit's popularity algorithms promote information about COVID-19?**

<!-- CAT Lab Logo (float right) -->
<img src="../assets/CAT-square-logo.png" width="150" align="right" style="margin:10px;"/>


Since 2016, the [Citizens and Technology Lab](https://citizensandtech.org/about-cat-lab/) has taken ongoing snapshots of reddit's algorithms every 2-3 minutes. As we develop rapid-response citizen science studies with subreddits to test public health messaging, we have published our real-time data on reddit's algorithms with this dashboard.

During a pandemic, people need evolving information to guide our health decisions and what we share with others. These needs continue across the months-long [pandemic cycle of prevention, resilience, and recovery](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4504362/). 

Reddit is already a major hub of COVID-19 information for hundreds of millions worldwide. News and norms spread rapidly across the site, spread by algorithms that promote content from communities of tens of millions. Reddit memes, jokes, and ideas are also shared more widely online. While Reddit's ecosystem could improve safety, health, and well being, public health experts have also argued that [cascades of human and algorithm sharing are the biggest pandemic risk](https://www.nature.com/articles/d41586-018-07034-4). 

Another reason to monitor algorithms is that fact-checking interventions can have unexpected side-effects on ranking algorithms. In a large-scale experiment with r/worldnews on reddit, I found that [encouraging fact-checking influenced what reddit's popularity algorithms promoted by influencing human behavior](https://osf.io/m98b6/).

## How We Collect Data
This dashboard is generated every 30 minutes using the latest data within CAT Lab's research software. The output of this dashbaord is based on the last `r observation.period.days`. This dashboard uses three sources:
* snapshots every 2 minutes of two key reddit algorithms:
  * reddit's HOT algorithm, the default popularity ranking on the site
  * reddit's TOP algorithm
* data about posts, currently queried from Jason Baumgartner's [PushShift service](https://pushshift.io/)

With every report, we publish research-quality datasets to [covid-algotracker on github](https://github.com/natematias/covid-algotracker/tree/master/data-archive/reddit), along with information about the settings, keywords, and software behind the data.

## How We Identify COVID-19 Posts
This report identified a post as related to COVID-19 if the lower-case title or the text of the submission matched any of the following terms ([code here](https://github.com/natematias/covid-algotracker/blob/master/scripts/fetch-reddit-frontpage.py)):

````{r echo = FALSE, results=TRUE}
config.json$terms
````

# Currently-Promoted COVID-19 Posts on Reddit

## Posts Currently Promoted by the HOT Algorithm

In the latest snapshot, `r sprintf("%.01f", (sum(latest.hot.posts$covid_19.x) / nrow(latest.hot.posts))*100)`% of posts appearing in the HOT algorithm on reddit are COVID-19 related.

<ul>
````{r echo = FALSE, results='asis'}
apply(subset(latest.hot.posts, covid_19.x==1), 1, FUN=cat.post, ranking="hot")
````
</ul>

````{r echo = FALSE, results=FALSE, fig.width=10, fig.height=3}

min.hot.xlim = floor(min(subset(latest.hot.rank.snapshots, is.na(rank_position)!=T)$age.minutes)/60)*60

ggplot(latest.hot.rank.snapshots, aes(age.minutes, rank_position, group=id, col=factor(covid_19))) +
    geom_line() + 
    cat.theme +
    scale_colour_manual(values = covidpalette, name="COVID-19\nrelated") +
    scale_x_continuous(breaks=seq(min.hot.xlim, 0, 60), limits=c(min.hot.xlim, 0)) + 
    ylab("Rank position")  +
    ggtitle("Rank Position of COVID-19 Posts currently the front page of reddit (HOT)") +
    xlab(paste("Minutes prior to the snapshot (up to ",abs(min.hot.xlim/60), " hours)", sep=""))

````

## Posts Currently Promoted by the TOP Algorithm


In the latest snapshot, `r sprintf("%.01f", (sum(latest.top.posts$covid_19.x) / nrow(latest.top.posts))*100)`% of posts appearing in the TOP algorithm on reddit are COVID-19 related.

<ul>
````{r echo = FALSE, results='asis'}
apply(subset(latest.top.posts, covid_19.x==1), 1, FUN=cat.post, ranking="top")
````
</ul>


````{r echo=FALSE, results=FALSE, fig.width=10, fig.height=3}
min.top.xlim = floor(min(subset(latest.top.rank.snapshots, is.na(rank_position)!=T)$age.minutes)/60)*60

ggplot(latest.top.rank.snapshots, aes(age.minutes, rank_position, group=id, col=factor(covid_19))) +
    geom_line() + 
    cat.theme +
    scale_colour_manual(values = covidpalette, name="COVID-19\nrelated") +
    scale_x_continuous(breaks=seq(min.top.xlim, 0, 60), limits=c(min.top.xlim, 0)) + 
    ylab("Rank position")  +
    ggtitle("Rank Position of COVID-19 Posts currently the front page of reddit (TOP)") +
    xlab(paste("Minutes prior to the snapshot (up to ",abs(min.top.xlim/60), " hours)", sep=""))
````

# Communities and Sources

## Communities and Sources Promoted by Reddit's HOT Algorithm

```{r echo=FALSE, results=TRUE}
num.top.obs = 15

recent.subs <- as.data.frame(table(as.character(subset(recent.posts, covid_19==1)$subreddit)))
recommended.subs <- head(recent.subs[order(-recent.subs$Freq),], num.top.obs)
row.names(recommended.subs) <- recommended.subs$Var1
names(recommended.subs) <- c("subreddit", "frequency")
kable(recommended.subs[c("frequency")],
    caption=paste("Top ", num.top.obs, " subreddits with COVID-19 content promoted by reddit's algorithms in the past ",
                  observation.period.days, " days.",sep=""))

````


```{r echo=FALSE, results=TRUE}
recent.domains <- as.data.frame(table(as.character(subset(recent.posts, covid_19==1)$domain)))
recommended.domains <- head(recent.domains[order(-recent.domains$Freq),], num.top.obs)
row.names(recommended.domains) <- recommended.domains$Var1
names(recommended.domains) <- c("domain", "frequency")
kable(recommended.domains[c("frequency")],
    caption=paste("Top ",num.top.obs," web domains with COVID-19 content promoted by reddit's algorithms in the past ",
                  observation.period.days, " days.",sep=""))

````

# How to Help
We have been working with r/science moderators on public health interventions since COVID-19 reached the US. We have lined up collaborations with communities of tens of millions on reddit and are currently fundraising support for a coordinator to help us organize redditors to expand the quality and timeliness of public health information on reddit. We developed this dashboard to guide our own efforts, and also to showcase the information available to our software for community-led behavioral research on reddit.

If your community is interested to join us, **TODO: TAKE ACTION**

If you can help us find the resources to hire a part-time coordinator, please contact J. Nathan Matias nathan.matias@cornell.edu. CAT Lab is a proudly [industry-independent](https://citizensandtech.org/2020/01/industry-independent-research/) research lab at Cornell University.

# About CAT Lab
The [Citizens and Technology Lab](https://citizensandtech.org) at Cornell University with communities to study the social impacts of digital technologies and discover effective ideas for change. CAT Lab is led by [Dr. J. Nathan Matias](https://natematias.com), an assistant professor in the department of Communication.

Working with communities and movements, we discover practical knowledge that also contributes to science, holds companies accountable, and is guided by the people most affected. Communities bring their problems, deep knowledge, and desire for change. We offer our expertise in scientific research and a software platform for coordinating citizen behavioral science.

# References and Further Reading

* Larson, H. J. (2018). [The biggest pandemic risk? Viral misinformation](https://www.nature.com/articles/d41586-018-07034-4). Nature, 562(7726), 309-310.
* Matias, J. N. (2019). [Preventing harassment and increasing group participation through social norms in 2,190 online science discussions](https://www.pnas.org/content/early/2019/04/23/1813486116). Proceedings of the National Academy of Sciences, 116(20), 9785-9789.
* Matias, J. N. (pre-print, 2018). [Nudging Algorithms by Influencing Human Behavior. Effects of Encouraging Fact-Checking on News Algorithms](https://osf.io/m98b6/). https://osf.io/m98b6/
* Matias, J. N., & Mou, M. (2018, April). [CivilServant: Community-led experiments in platform governance](https://natematias.com/media/Community_Led_Experiments-CHI_2018.pdf). In Proceedings of the 2018 CHI conference on human factors in computing systems (pp. 1-13).
* Vaughan, E., & Tinker, T. (2009). [Effective health risk communication about pandemic influenza for vulnerable populations](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4504362/). American Journal of Public Health, 99(S2), S324-S332.

